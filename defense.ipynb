{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1132e1e0-d39c-47ae-8045-24adf798151a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom selenium.webdriver.support.ui import WebDriverWait\\nfrom selenium.webdriver.support import expected_conditions as EC\\nfrom selenium.webdriver.common.by import By\\nfrom selenium.common.exceptions import NoSuchElementException\\nfrom selenium.common.exceptions import ElementNotInteractableException \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import string\n",
    "#url_list = [cs,pullup]\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "'''\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf515d41-2280-4782-8715-3310d670bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-24\n",
      "2024\n",
      "2023-24\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pull_data(url):\n",
    "    headers = {\n",
    "                                    \"Host\": \"stats.nba.com\",\n",
    "                                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:72.0) Gecko/20100101 Firefox/72.0\",\n",
    "                                    \"Accept\": \"application/json, text/plain, */*\",\n",
    "                                    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "                                    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\n",
    "                                    \"Connection\": \"keep-alive\",\n",
    "                                    \"Referer\": \"https://stats.nba.com/\"\n",
    "                                }\n",
    "    json = requests.get(url,headers = headers).json()\n",
    "    data = json[\"resultSets\"][0][\"rowSet\"]\n",
    "    columns = json[\"resultSets\"][0][\"headers\"]\n",
    "    df = pd.DataFrame.from_records(data, columns=columns)\n",
    "    return df\n",
    "def get_index():\n",
    "    teams_response = requests.get(\"https://api.pbpstats.com/get-teams/nba\")\n",
    "    teams = teams_response.json()\n",
    "    team_dict = {}\n",
    "    for team in teams['teams']:\n",
    "        team_dict[team['text']] = team['id']\n",
    "    players_response = requests.get(\"https://api.pbpstats.com/get-all-players-for-league/nba\")\n",
    "    players = players_response.json()[\"players\"]\n",
    "    player_dict = dict([(player.lower(),num) for num,player in players.items()])\n",
    "  \n",
    "    return player_dict,team_dict\n",
    "def update_master(master_file,new_file,year):\n",
    "    df = pd.read_csv(new_file)\n",
    "    old = pd.read_csv(master_file)\n",
    "    old = old[old.year!=year]\n",
    "    df['year'] = year\n",
    "    old = pd.concat([old,df])\n",
    "    old.to_csv(master_file,index = False)\n",
    "def get_ptables(url_list,path_list):\n",
    "    data = []\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    cookie_check = False\n",
    "    \n",
    "    for i in range(len(url_list)):\n",
    "        url = url_list[i]\n",
    "        xpath = path_list[i]\n",
    "        print(url)\n",
    "        \n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to fully load\n",
    "\n",
    "        driver.implicitly_wait(10)\n",
    "        '''if check_exists_by_xpath(driver, \"//a[contains(text(),'>')]/preceding-sibling::a[1]\"):\n",
    "            number_of_pages = int(driver.find_element(By.XPATH, \"//a[contains(text(),'>')]/preceding-sibling::a[1]\").text)\n",
    "            print(number_of_pages)'''\n",
    "        accept_path = '//*[@id=\"onetrust-accept-btn-handler\"]'\n",
    "        time.sleep(4)\n",
    "        if EC.presence_of_element_located((By.XPATH, accept_path)) and cookie_check == False:\n",
    "            driver.find_element(By.XPATH, accept_path).click() \n",
    "            cookie_check = True\n",
    "            time.sleep(1)\n",
    "        element = WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        \n",
    "        dropdown1 = Select(driver.find_element(By.XPATH, xpath))\n",
    "        dropdown1.select_by_index(0)\n",
    "\n",
    "        # Step 2: Parse HTML code and grab tables with Beautiful Soup\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "\n",
    "        # Step 3: Read tables with Pandas read_html()\n",
    "        dfs = pd.read_html(str(tables))\n",
    "        #print(dfs)\n",
    "\n",
    "        #print(f'Total tables: {len(dfs)}')\n",
    "        #print(dfs[2].head())\n",
    "    \n",
    "        \n",
    "        #return dfs\n",
    "        df= dfs[-1]\n",
    "        #drop = ['Unnamed: 16_level_1', 'Unnamed: 17_level_1', 'Unnamed: 18_level_1']\n",
    "        #df.columns = df.columns.droplevel()\n",
    "        #df = df.drop(columns = drop)\n",
    "       \n",
    "        data.append(df)\n",
    "    driver.close()\n",
    "    return data\n",
    "def get_defense(url,year,ps = False):\n",
    "    \n",
    "    defense = url\n",
    "    url_list = [defense]\n",
    "    #url_list =[url +'&SeasonType=Regular+Season'for url in url_list]\n",
    "    url_list =[defense+'&Season='+str(year)+'-'+str(year+1 - 2000)]\n",
    "    if ps == False:\n",
    "        url_list =[url +'&SeasonType=Regular+Season'for url in url_list]\n",
    "        path = str(year+1) +'/defense/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        filename = path+ 'dfg.csv'\n",
    "    else:\n",
    "        url_list = [ url+'&SeasonType=Playoffs'for url in url_list]\n",
    "        path = str(year+1) + '/playoffs/'+'defense/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        filename = path+'dfg_p.csv'\n",
    "   \n",
    "        \n",
    "\n",
    "    xpath = '//*[@id=\"__next\"]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select'\n",
    "    #xpath2 = '//*[@id=\"__next\"]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select'\n",
    "    path_list = [xpath for i in range(len(url_list))]\n",
    "    frames = get_ptables(url_list,path_list)\n",
    "    \n",
    "    df = frames[0]\n",
    "    df['year'] = year\n",
    "    return df\n",
    "def prep_dfg(dfg):\n",
    "    dfg = dfg.drop(columns = ['CLOSE_DEF_PERSON_ID','PLAYER_LAST_TEAM_ID'])\n",
    "    dfg.columns = ['PLAYER', 'TEAM', 'AGE', 'POSITION', 'GP', 'G', 'FREQ%', 'DFGM', 'DFGA',\n",
    "       'DFG%', 'FG%', 'DIFF%']\n",
    "    for col in dfg:\n",
    "        if '%' in col:\n",
    "            dfg[col]*=100\n",
    "    return dfg\n",
    "def wowy_statlog(stat,start_year,ps =False):\n",
    "    if ps == False:\n",
    "        s_type = 'Regular Season'\n",
    "    elif ps == 'all':\n",
    "        s_type = 'All'\n",
    "    else:\n",
    "        s_type = 'Playoffs'\n",
    "        print('Playoffs')\n",
    "    player_dict,team_dict= get_index()\n",
    "    frames = []\n",
    "    for season in range(start_year,2025):\n",
    "        if (season)%100 <=9:\n",
    "            zero = '0'\n",
    "        else:\n",
    "            zero = ''\n",
    "        season_s = str(season-1)+'-'+zero+str((season)%100)\n",
    "        print(season_s)\n",
    "        url = \"https://api.pbpstats.com/get-on-off/nba/stat\"\n",
    "        for team in team_dict.keys():\n",
    "            params = {\n",
    "                \"Season\": season_s,\n",
    "                \"SeasonType\": s_type,\n",
    "                \"TeamId\": team_dict[team],\n",
    "                \"Stat\": stat, # for all options for Stat, see the list below\n",
    "\n",
    "            }\n",
    "            response = requests.get(url, params=params)\n",
    "            response_json = response.json()\n",
    "            #print(response_json)\n",
    "            df = pd.DataFrame(response_json['results'])\n",
    "            df['Team'] = team\n",
    "            df['Year'] = season\n",
    "            df['Season'] = season_s\n",
    "            #print(df)\n",
    "            #break\n",
    "            #print(df)\n",
    "            frames.append(df)\n",
    "        print(season)\n",
    "    return pd.concat(frames)\n",
    "def update_log(filename,stat,ps = False):\n",
    "\n",
    "    df = wowy_statlog(stat,2024,ps)\n",
    "    df.to_csv(filename,index =False)\n",
    "    \n",
    "#stat = 'FG2APctBlocked'\n",
    "# At Rim Shot Frequency - Defense\n",
    "stat= \"AtRimAccuracyOpponent\"\n",
    "filename = '2024/defense/rim_acc.csv'\n",
    "update_log(filename,stat)\n",
    "#filename = '2023/playoffs/defense/rim_acc_p.csv'\n",
    "\n",
    "\n",
    "#update_log(filename,stat,ps = False)\n",
    "#update_master('rim_acc.csv',filename)\n",
    "\n",
    "stat2 =\"AtRimFrequencyOpponent\"\n",
    "\n",
    "\n",
    "#update_log(filename,stat2)\n",
    "\n",
    "#filename = '2023/playoffs/defense/rimfreq_p.csv'\n",
    "filename = '2024/defense/rimfreq.csv'\n",
    "update_log(filename,stat2,ps = False)\n",
    "\n",
    "def update_dash():\n",
    "    \n",
    "    url=\"https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom=&DateTo=&DefenseCategory=Overall&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season=2023-24&SeasonSegment=&SeasonType=Regular%20Season&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\"\n",
    "\n",
    "    df = pull_data(url)\n",
    "    df = prep_dfg(df)\n",
    "    old = pd.read_csv('dfg.csv')\n",
    "    old = old[old.year!=2023]\n",
    "    df['year'] = 2024\n",
    "    df = df.round(2)\n",
    "    old = pd.concat([old,df])\n",
    "    old.to_csv('dfg.csv',index = False)\n",
    "    \n",
    "    df.to_csv('2024/defense/dfg.csv',index = False)\n",
    "    \n",
    "    url = \"https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom=&DateTo=&DefenseCategory=Less%20Than%206Ft&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season=2023-24&SeasonSegment=&SeasonType=Regular%20Season&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\"\n",
    "    \n",
    "    df = pull_data(url)\n",
    "    df = prep_dfg(df)\n",
    "    old = pd.read_csv('rimdfg.csv')\n",
    "    old = old[old.year!=2024]\n",
    "    df['year'] = 2024\n",
    "    df = df.round(2)\n",
    "    old = pd.concat([old,df])\n",
    "    old.to_csv('rimdfg.csv',index = False)\n",
    "    df.to_csv('2024/defense/rimdfg.csv',index = False)\n",
    "    \n",
    "\n",
    "#update_master('rimfreq.csv',filename)\n",
    "update_dash()\n",
    "#year = 2023\n",
    "#filename = '2023/defense/rim_acc.csv'\n",
    "#update_master('rim_acc.csv',filename,year)\n",
    "#year = 2023\n",
    "#filename = '2023/defense/rimfreq.csv'\n",
    "#update_master('rimfreq.csv',filename,year)\n",
    "year =2024\n",
    "filename = '2024/defense/rimfreq.csv'\n",
    "update_master('rimfreq.csv',filename,year)\n",
    "filename = '2024/defense/dfg.csv'\n",
    "update_master('dfg.csv',filename,year)\n",
    "filename = '2024/defense/rimdfg.csv'\n",
    "update_master('rimdfg.csv',filename,year)\n",
    "filename = '2024/defense/rim_acc.csv'\n",
    "update_master('rim_acc.csv',filename,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a7ea1a-384d-4be7-82e4-0315c59da827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_folders(new_folder):\n",
    "    for year in range(2014,2024):\n",
    "        path = str(year) +'/'+new_folder+'/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        path = str(year) +'/playoffs'+'/'+new_folder+'/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "create_folders('hustle')\n",
    "masters =['rimfreq','rim_acc','dfg']\n",
    "#temp = pd.read_csv('dfg_p.csv')\n",
    "#temp = temp.rename(columns = {'year':'Year'})\n",
    "#temp.to_csv('dfg_p.csv',index = False)\n",
    "def update_masters(year,masters,ps = False):\n",
    "    \n",
    "    if ps == False:\n",
    "        trail = ''\n",
    "        path = str(year)+'/defense/'\n",
    "    else:\n",
    "        trail = '_p'\n",
    "        path = str(year)+'/playoffs/defense/'\n",
    "    for file in masters:\n",
    "        print(file)\n",
    "        df = pd.read_csv(file+trail+'.csv')\n",
    "        df = df[df.year<year]\n",
    "        new = pd.read_csv(path+file+trail+'.csv')\n",
    "        df = pd.concat([df,new])\n",
    "        df.to_csv(file+trail+'csv',index = False)\n",
    "#update_masters(2023,masters,ps = False)\n",
    "#temp = pd.read_csv('dfg_p.csv')\n",
    "#temp = temp.rename(columns = {'Year':'year'})\n",
    "#temp.to_csv('dfg_p.csv',index = False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5074e54-1e0b-4bcf-bb30-b97c28b58eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename = 'dfg_p.csv'\\ndf = pd.read_csv(filename)\\nfor year in range(2014,2024):\\n    ps = '/playoffs/'\\n    #ps = ''\\n    path = str(year) +ps+'/defense/'\\n    year_df = df[df.year==year]\\n    print(year_df)\\n    year_df.to_csv(path+'dfg.csv',index = False)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "filename = 'dfg_p.csv'\n",
    "df = pd.read_csv(filename)\n",
    "for year in range(2014,2024):\n",
    "    ps = '/playoffs/'\n",
    "    #ps = ''\n",
    "    path = str(year) +ps+'/defense/'\n",
    "    year_df = df[df.year==year]\n",
    "    print(year_df)\n",
    "    year_df.to_csv(path+'dfg.csv',index = False)\n",
    "'''  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
