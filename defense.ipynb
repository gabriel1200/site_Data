{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1132e1e0-d39c-47ae-8045-24adf798151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playoffs\n",
      "2023\n",
      "Playoffs\n",
      "2023\n",
      "https://www.nba.com/stats/players/defense-dash-lt6?PerMode=Totals&Season=2022-23&SeasonType=Playoffs\n",
      "https://www.nba.com/stats/players/defense-dash-overall?PerMode=Totals&Season=2022-23&SeasonType=Playoffs\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import string\n",
    "#url_list = [cs,pullup]\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException \n",
    "def get_index():\n",
    "    teams_response = requests.get(\"https://api.pbpstats.com/get-teams/nba\")\n",
    "    teams = teams_response.json()\n",
    "    team_dict = {}\n",
    "    for team in teams['teams']:\n",
    "        team_dict[team['text']] = team['id']\n",
    "    players_response = requests.get(\"https://api.pbpstats.com/get-all-players-for-league/nba\")\n",
    "    players = players_response.json()[\"players\"]\n",
    "    player_dict = dict([(player.lower(),num) for num,player in players.items()])\n",
    "  \n",
    "    return player_dict,team_dict\n",
    "def update_master(master_file,new_file):\n",
    "    df = pd.read_csv(new_file)\n",
    "    old = pd.read_csv(master_file)\n",
    "    old = old[old.Year!=2023]\n",
    "    df['year'] = 2023\n",
    "    old = pd.concat([old,df])\n",
    "    old.to_csv(master_file,index = False)\n",
    "def get_ptables(url_list,path_list):\n",
    "    data = []\n",
    "    driver = webdriver.Chrome()\n",
    "    for i in range(len(url_list)):\n",
    "        url = url_list[i]\n",
    "        xpath = path_list[i]\n",
    "        print(url)\n",
    "        \n",
    "        driver.get(url)\n",
    "        element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        # Wait for the page to fully load\n",
    "        driver.implicitly_wait(10)\n",
    "        '''if check_exists_by_xpath(driver, \"//a[contains(text(),'>')]/preceding-sibling::a[1]\"):\n",
    "            number_of_pages = int(driver.find_element(By.XPATH, \"//a[contains(text(),'>')]/preceding-sibling::a[1]\").text)\n",
    "            print(number_of_pages)'''\n",
    "        \n",
    "        dropdown1 = Select(driver.find_element(By.XPATH, xpath))\n",
    "        dropdown1.select_by_index(0)\n",
    "\n",
    "        # Step 2: Parse HTML code and grab tables with Beautiful Soup\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "\n",
    "        # Step 3: Read tables with Pandas read_html()\n",
    "        dfs = pd.read_html(str(tables))\n",
    "        #print(dfs)\n",
    "\n",
    "        #print(f'Total tables: {len(dfs)}')\n",
    "        #print(dfs[2].head())\n",
    "    \n",
    "        \n",
    "        #return dfs\n",
    "        df= dfs[-1]\n",
    "        #drop = ['Unnamed: 16_level_1', 'Unnamed: 17_level_1', 'Unnamed: 18_level_1']\n",
    "        #df.columns = df.columns.droplevel()\n",
    "        #df = df.drop(columns = drop)\n",
    "       \n",
    "        data.append(df)\n",
    "    driver.close()\n",
    "    return data\n",
    "def get_defense(url,year,ps = False):\n",
    "    \n",
    "    defense = url\n",
    "    url_list = [defense]\n",
    "    #url_list =[url +'&SeasonType=Regular+Season'for url in url_list]\n",
    "    url_list =[defense+'&Season='+str(year)+'-'+str(year+1 - 2000)]\n",
    "    if ps == False:\n",
    "        url_list =[url +'&SeasonType=Regular+Season'for url in url_list]\n",
    "        path = str(year+1) +'/defense/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        filename = path+ 'dfg.csv'\n",
    "    else:\n",
    "        url_list = [ url+'&SeasonType=Playoffs'for url in url_list]\n",
    "        path = str(year+1) + '/playoffs/'+'defense/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        filename = path+'dfg_p.csv'\n",
    "   \n",
    "        \n",
    "\n",
    "    xpath = '//*[@id=\"__next\"]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select'\n",
    "    #xpath2 = '//*[@id=\"__next\"]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select'\n",
    "    path_list = [xpath for i in range(len(url_list))]\n",
    "    frames = get_ptables(url_list,path_list)\n",
    "    \n",
    "    df = frames[0]\n",
    "    df['year'] = year\n",
    "    return df\n",
    "def wowy_statlog(stat,start_year,ps =False):\n",
    "    if ps == False:\n",
    "        s_type = 'Regular Season'\n",
    "    elif ps == 'all':\n",
    "        s_type = 'All'\n",
    "    else:\n",
    "        s_type = 'Playoffs'\n",
    "        print('Playoffs')\n",
    "    player_dict,team_dict= get_index()\n",
    "    frames = []\n",
    "    for season in range(start_year,2024):\n",
    "        if (season)%100 <=9:\n",
    "            zero = '0'\n",
    "        else:\n",
    "            zero = ''\n",
    "        season_s = str(season-1)+'-'+zero+str((season)%100)\n",
    "        url = \"https://api.pbpstats.com/get-on-off/nba/stat\"\n",
    "        for team in team_dict.keys():\n",
    "            params = {\n",
    "                \"Season\": season_s,\n",
    "                \"SeasonType\": s_type,\n",
    "                \"TeamId\": team_dict[team],\n",
    "                \"Stat\": stat, # for all options for Stat, see the list below\n",
    "\n",
    "            }\n",
    "            response = requests.get(url, params=params)\n",
    "            response_json = response.json()\n",
    "            #print(response_json)\n",
    "            df = pd.DataFrame(response_json['results'])\n",
    "            df['Team'] = team\n",
    "            df['Year'] = season\n",
    "            df['Season'] = season_s\n",
    "            #break\n",
    "            #print(df)\n",
    "            frames.append(df)\n",
    "        print(season)\n",
    "    return pd.concat(frames)\n",
    "def update_log(filename,stat,ps = False):\n",
    "\n",
    "    df = wowy_statlog(stat,2023,ps)\n",
    "    df.to_csv(filename,index =False)\n",
    "    \n",
    "#stat = 'FG2APctBlocked'\n",
    "# At Rim Shot Frequency - Defense\n",
    "stat= \"AtRimAccuracyOpponent\"\n",
    "filename = '2023/defense/rim_acc.csv'\n",
    "#update_log(filename,stat)\n",
    "filename = '2023/playoffs/defense/rim_acc_p.csv'\n",
    "\n",
    "\n",
    "update_log(filename,stat,ps = True)\n",
    "update_master('rim_acc_p.csv',filename)\n",
    "\n",
    "stat2 =\"AtRimFrequencyOpponent\"\n",
    "\n",
    "filename = '2023/defense/rimfreq.csv'\n",
    "#update_log(filename,stat2)\n",
    "\n",
    "filename = '2023/playoffs/defense/rimfreq_p.csv'\n",
    "update_log(filename,stat2,ps = True)\n",
    "update_master('rimfreq_p.csv',filename)\n",
    "\n",
    "def update_dash():\n",
    "    url = 'https://www.nba.com/stats/players/defense-dash-lt6?PerMode=Totals'\n",
    "    df = get_defense(url,2022,ps=True)\n",
    "    old = pd.read_csv('rimdfg_p.csv')\n",
    "    old = old[old.year!=2023]\n",
    "    df['year'] = 2023\n",
    "    old = pd.concat([old,df])\n",
    "    old.to_csv('rimdfg_p.csv',index = False)\n",
    "    df.to_csv('2023/playoffs/defense/rimdfg.csv',index = False)\n",
    "    \n",
    "    url = 'https://www.nba.com/stats/players/defense-dash-overall?PerMode=Totals'\n",
    "    df = get_defense(url,2022,ps=True)\n",
    "    old = pd.read_csv('dfg_p.csv')\n",
    "    old = old[old.year!=2023]\n",
    "    df['year'] = 2023\n",
    "    old = pd.concat([old,df])\n",
    "    old.to_csv('dfg_p.csv',index = False)\n",
    "    df.to_csv('2023/playoffs/defense/dfg.csv',index = False)\n",
    "    \n",
    "\n",
    "update_dash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d5a82-296e-4dee-a1ba-b8698d803d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2acd1e6-3a83-45c1-98d5-a013d398b982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91a7ea1a-384d-4be7-82e4-0315c59da827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rimfreq\n",
      "rim_acc\n",
      "dfg\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def create_folders():\n",
    "    for year in range(2014,2024):\n",
    "        path = str(year) +'/defense/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        path = str(year) +'/playoffs'+'/defense/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# create_folders()\n",
    "masters =['rimfreq','rim_acc','dfg']\n",
    "temp = pd.read_csv('dfg_p.csv')\n",
    "temp = temp.rename(columns = {'year':'Year'})\n",
    "temp.to_csv('dfg_p.csv',index = False)\n",
    "def update_masters(year,masters,ps = False):\n",
    "    \n",
    "    if ps == False:\n",
    "        trail = ''\n",
    "        path = str(year)+'/defense/'\n",
    "    else:\n",
    "        trail = '_p'\n",
    "        path = str(year)+'/playoffs/defense/'\n",
    "    for file in masters:\n",
    "        print(file)\n",
    "        df = pd.read_csv(file+trail+'.csv')\n",
    "        df = df[df.Year<year]\n",
    "        new = pd.read_csv(path+file+trail+'.csv')\n",
    "        df = pd.concat([df,new])\n",
    "        df.to_csv(file+trail+'csv',index = False)\n",
    "update_masters(2023,masters,ps = True)\n",
    "temp = pd.read_csv('dfg_p.csv')\n",
    "temp = temp.rename(columns = {'Year':'year'})\n",
    "temp.to_csv('dfg_p.csv',index = False)     \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5074e54-1e0b-4bcf-bb30-b97c28b58eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename = 'dfg_p.csv'\\ndf = pd.read_csv(filename)\\nfor year in range(2014,2024):\\n    ps = '/playoffs/'\\n    #ps = ''\\n    path = str(year) +ps+'/defense/'\\n    year_df = df[df.year==year]\\n    print(year_df)\\n    year_df.to_csv(path+'dfg.csv',index = False)\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "filename = 'dfg_p.csv'\n",
    "df = pd.read_csv(filename)\n",
    "for year in range(2014,2024):\n",
    "    ps = '/playoffs/'\n",
    "    #ps = ''\n",
    "    path = str(year) +ps+'/defense/'\n",
    "    year_df = df[df.year==year]\n",
    "    print(year_df)\n",
    "    year_df.to_csv(path+'dfg.csv',index = False)\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89514d-3594-4795-8c7e-fe79f4c95106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
