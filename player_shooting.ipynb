{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee039b43-d076-4991-9024-a24a2645f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#url_list = [url1]#\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "# Step 1: Create a session and load the page\n",
    "url4 = 'https://www.nba.com/stats/players/shots-closest-defender?CloseDefDistRange=6%2B+Feet+-+Wide+Open&PerMode=Totals'\n",
    "url3 = 'https://www.nba.com/stats/players/shots-closest-defender?CloseDefDistRange=4-6+Feet+-+Open&PerMode=Totals'\n",
    "url2 = 'https://www.nba.com/stats/players/shots-closest-defender?CloseDefDistRange=2-4+Feet+-+Tight&PerMode=Totals'\n",
    "url1 = 'https://www.nba.com/stats/players/shots-closest-defender?CloseDefDistRange=0-2+Feet+-+Very+Tight&PerMode=Totals'\n",
    "url_list = [url1,url2,url3,url4]\n",
    "#url_list = url_list.reverse()\n",
    "print(url_list)\n",
    "#url_list =[url +'&SeasonType=Playoffs' for url in url_list]\n",
    "#url_list =[url +'&SeasonType=Regular+Season'for url in url_list]\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "\n",
    "def get_tables(url_list):\n",
    "    data = []\n",
    "    xpath = '//*[@id=\"__next\"]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select'\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    #driver = webdriver.Chrome()\n",
    "    for url in url_list:\n",
    "        \n",
    "        driver.get(url)\n",
    "        print(url)\n",
    "        # Wait for the page to fully load\n",
    "        driver.implicitly_wait(20)\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        driver.implicitly_wait(10)\n",
    "        '''if check_exists_by_xpath(driver, \"//a[contains(text(),'>')]/preceding-sibling::a[1]\"):\n",
    "            number_of_pages = int(driver.find_element(By.XPATH, \"//a[contains(text(),'>')]/preceding-sibling::a[1]\").text)\n",
    "            print(number_of_pages)'''\n",
    "        time.sleep(10)\n",
    "        dropdown1 = Select(driver.find_element(By.XPATH, xpath))\n",
    "        dropdown1.select_by_index(0)\n",
    "\n",
    "        # Step 2: Parse HTML code and grab tables with Beautiful Soup\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        \n",
    "\n",
    "        tables = soup.find_all('table')\n",
    "\n",
    "        # Step 3: Read tables with Pandas read_html()\n",
    "        dfs = pd.read_html(str(tables))\n",
    "\n",
    "        #print(f'Total tables: {len(dfs)}')\n",
    "        #print(dfs[2].head())\n",
    "\n",
    "        \n",
    "        df= dfs[-1]\n",
    "        print(len(df))\n",
    "        #print(df)\n",
    "    \n",
    "        df.columns = df.columns.droplevel()\n",
    "        drop = [ 'Unnamed: 18_level_1', 'Unnamed: 19_level_1','Unnamed: 20_level_1','Unnamed: 21_level_1','Unnamed: 22_level_1']\n",
    "        df = df.drop(columns = drop)\n",
    "        #df = df.drop(columns = drop)\n",
    "        data.append(df)\n",
    "    driver.close()\n",
    "    return data\n",
    "def get_multi(url_list,playoffs = False):\n",
    "    if playoffs == True:\n",
    "        p ='/playoffs'\n",
    "        url_list =[url +'&SeasonType=Playoffs' for url in url_list]\n",
    "    else:\n",
    "        p = ''\n",
    "        url_list =[url +'&SeasonType=Regular+Season'for url in url_list]\n",
    "        \n",
    "    for i in range(2023,2024):\n",
    "        \n",
    "        season = '&Season='+str(i)+'-'+str(i+1 - 2000)\n",
    "        year_url = [url+season for url in url_list]\n",
    "        frames = get_tables(year_url)\n",
    "\n",
    " \n",
    "        path = str(i+1)+p+'/player_shooting/'\n",
    "        output_dir = Path(path)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        #terms = ['data/teampullup.csv','data/teamcatchshoot.csv','data/teamundersix.csv','data/teamiso.csv','data/teamtransition.csv']\n",
    "        terms = ['very_tight.csv','tight.csv','open.csv','wide_open.csv']\n",
    "        terms = [ path+ t for t in terms]\n",
    "        \n",
    "        for i in range(len(terms)):\n",
    "            df = frames[i]\n",
    "            #print(df)\n",
    "            #print(terms[i])\n",
    "            df.to_csv(terms[i],index = False)\n",
    "\n",
    "#get_multi(url_list)\n",
    "get_multi(url_list,playoffs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e0373-180e-44c1-b99c-36285765c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_shooting(playoffs = False):\n",
    "    data =[]\n",
    "    for i in range(2014,2024):\n",
    "        if playoffs == False:\n",
    "            p = ''\n",
    "        else:\n",
    "            p='/playoffs'\n",
    "\n",
    "        path = str(i)+p+'/player_shooting/'\n",
    "        files = ['wide_open','open','tight','very_tight']\n",
    "        for file in files:\n",
    "            df = pd.read_csv(path+file+'.csv.')\n",
    "            df['year'] = i\n",
    "            df['shot_type'] =file\n",
    "            data.append(df)\n",
    "    master = pd.concat(data)\n",
    "    return master\n",
    "master= master_shooting() \n",
    "master.to_csv('player_shooting.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f264283-678e-47a0-be28-4bf209cc6aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
