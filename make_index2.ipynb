{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in REGULAR SEASON mode\n",
      "==================================================\n",
      "NBA Data Scraper - 2024-25 Regular Season\n",
      "==================================================\n",
      "Loaded master index with 29217 entries\n",
      "\n",
      "--- Processing Totals Data ---\n",
      "Fetching data from: https://www.basketball-reference.com/leagues/NBA_2025_totals.html\n",
      "Found 32 column headers\n",
      "Header mapping: {'ranker': 0, 'name_display': 1, 'age': 2, 'team_name_abbr': 3, 'pos': 4, 'games': 5, 'games_started': 6, 'mp': 7, 'fg': 8, 'fga': 9, 'fg_pct': 10, 'fg3': 11, 'fg3a': 12, 'fg3_pct': 13, 'fg2': 14, 'fg2a': 15, 'fg2_pct': 16, 'efg_pct': 17, 'ft': 18, 'fta': 19, 'ft_pct': 20, 'orb': 21, 'drb': 22, 'trb': 23, 'ast': 24, 'stl': 25, 'blk': 26, 'tov': 27, 'pf': 28, 'pts': 29, 'tpl_dbl': 30, 'awards': 31}\n",
      "Found 736 player entries for 2025\n",
      "Successfully processed 736 players for 2025 (totals)\n",
      "Sample player: N/A - N/A\n",
      "Processing player IDs for 736 players\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 5 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 424\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 424\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 390\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m totals_frame \u001b[38;5;241m=\u001b[39m pull_bref_data(totals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m totals_frame\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m--> 390\u001b[0m     totals_frame \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_player_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotals_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     totals_frame \u001b[38;5;241m=\u001b[39m calculate_true_shooting(totals_frame)\n\u001b[1;32m    392\u001b[0m     master \u001b[38;5;241m=\u001b[39m update_master_index(totals_frame, master)\n",
      "Cell \u001b[0;32mIn[9], line 202\u001b[0m, in \u001b[0;36mprocess_player_ids\u001b[0;34m(df, master_df)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing player IDs for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m players\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Extract Basketball Reference IDs\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbref_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Create ID mapping dictionary from master\u001b[39;00m\n\u001b[1;32m    205\u001b[0m match_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbref_id\u001b[39m\u001b[38;5;124m'\u001b[39m], master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnba_id\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 5"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from nba_api.stats.endpoints import commonallplayers\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    # Set to True for playoffs data, False for regular season\n",
    "    PLAYOFFS_MODE = True\n",
    "    # Current year to scrape\n",
    "    CURRENT_YEAR = 2025\n",
    "    # Current season in NBA API format\n",
    "    CURRENT_SEASON = \"2024-25\"\n",
    "    # File paths with dynamic playoff suffix\n",
    "    @property\n",
    "    def trail(self):\n",
    "        return '_ps' if self.PLAYOFFS_MODE else ''\n",
    "    \n",
    "    @property\n",
    "    def index_master_path(self):\n",
    "        return f'index_master{self.trail}.csv'\n",
    "    \n",
    "    @property\n",
    "    def totals_path(self):\n",
    "        return f'totals{self.trail}.csv'\n",
    "    \n",
    "    @property\n",
    "    def scoring_path(self):\n",
    "        return f'scoring{self.trail}.csv'\n",
    "    \n",
    "    # Hard-coded player IDs for players that might be missing\n",
    "    SEARCH_DICT = {\n",
    "        \"hollaro01\": 1641842,\n",
    "        \"sarral01\": 1642259,\n",
    "        \"dadiepa01\": 1642359,\n",
    "        \"cuiyo01\": 1642385,\n",
    "        \"dasiltr01\": 1641783,\n",
    "        \"salauti01\": 1642275,\n",
    "        \"shannte01\": 1630545,\n",
    "        \"sengual01\":1630578,\n",
    "        \"willije02\":1631466\n",
    "\n",
    "    }\n",
    "\n",
    "# Initialize config\n",
    "config = Config()\n",
    "print(f\"Running in {'PLAYOFFS' if config.PLAYOFFS_MODE else 'REGULAR SEASON'} mode\")\n",
    "\n",
    "def fetch_data(url):\n",
    "    \"\"\"Fetch data from a URL with proper error handling\"\"\"\n",
    "    print(f\"Fetching data from: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.encoding = 'utf-8'\n",
    "        if response.status_code != 200:\n",
    "            print(f\"ERROR: Received status code {response.status_code}\")\n",
    "            return None\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to fetch data: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_table_headers(table):\n",
    "    \"\"\"Parse table headers and return a mapping of column indices to data stats\"\"\"\n",
    "    header_mapping = {}\n",
    "    headers = table.find('thead').find_all('th')\n",
    "    \n",
    "    for i, header in enumerate(headers):\n",
    "        data_stat = header.get('data-stat')\n",
    "        if data_stat:\n",
    "            header_mapping[data_stat] = i\n",
    "    \n",
    "    print(f\"Found {len(header_mapping)} column headers\")\n",
    "    print(f\"Header mapping: {header_mapping}\")\n",
    "    return header_mapping\n",
    "\n",
    "def get_cell_value(row, header_mapping, stat_name, default_value=\"0\"):\n",
    "    \"\"\"Get cell value based on header mapping\"\"\"\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    if stat_name in header_mapping and header_mapping[stat_name] < len(cells):\n",
    "        cell = cells[header_mapping[stat_name]]\n",
    "        return cell.text.strip() if cell.text.strip() else default_value\n",
    "    return default_value\n",
    "\n",
    "def get_player_url(row, header_mapping):\n",
    "    \"\"\"Get player URL from the row\"\"\"\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    player_index = header_mapping.get('player', 0)\n",
    "    if player_index < len(cells):\n",
    "        player_cell = cells[player_index]\n",
    "        player_link = player_cell.find('a')\n",
    "        if player_link and player_link.has_attr('href'):\n",
    "            return \"https://www.basketball-reference.com\" + player_link['href']\n",
    "    return \"N/A\"\n",
    "\n",
    "def pull_bref_data(totals=False):\n",
    "    \"\"\"Pull data from Basketball Reference using dynamic header mapping\"\"\"\n",
    "    leagues = \"playoffs\" if config.PLAYOFFS_MODE else \"leagues\"\n",
    "    frames = []\n",
    "    \n",
    "    # Determine URL based on data type\n",
    "    if totals:\n",
    "        url_pattern = f\"https://www.basketball-reference.com/{leagues}/NBA_{{year}}_totals.html\"\n",
    "        data_type = \"totals\"\n",
    "    else:\n",
    "        url_pattern = f\"https://www.basketball-reference.com/{leagues}/NBA_{{year}}_per_poss.html\"\n",
    "        data_type = \"per possession\"\n",
    "    \n",
    "    # Only scrape current year\n",
    "    url = url_pattern.format(year=config.CURRENT_YEAR)\n",
    "    html_content = fetch_data(url)\n",
    "    if not html_content:\n",
    "        print(f\"Skipping {config.CURRENT_YEAR}, couldn't fetch data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    if not table:\n",
    "        print(f\"No table found for {config.CURRENT_YEAR}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Parse headers to get column mapping\n",
    "    header_mapping = parse_table_headers(table)\n",
    "    \n",
    "    # Find table body\n",
    "    tbody = table.find('tbody')\n",
    "    if not tbody:\n",
    "        print(f\"No table body found for {config.CURRENT_YEAR}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all rows\n",
    "    rows = tbody.find_all('tr')\n",
    "    print(f\"Found {len(rows)} player entries for {config.CURRENT_YEAR}\")\n",
    "    \n",
    "    # Extract data\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        # Skip header rows\n",
    "        if 'thead' in row.get('class', []) or row.get('class') == ['thead']:\n",
    "            continue\n",
    "            \n",
    "        # Get values using header mapping\n",
    "        player_name = get_cell_value(row, header_mapping, 'player', \"N/A\")\n",
    "        player_url = get_player_url(row, header_mapping)\n",
    "        team_acronym = get_cell_value(row, header_mapping, 'team_id', \"N/A\")\n",
    "        \n",
    "        # Get the stats - handle both normal and per_poss stats\n",
    "        gp = get_cell_value(row, header_mapping, 'g', \"0\")\n",
    "        mp = get_cell_value(row, header_mapping, 'mp', \"0\")\n",
    "        \n",
    "        # Get shooting stats - handle both normal and per_poss stats\n",
    "        if totals:\n",
    "            # Total stats use standard column names\n",
    "            fg = get_cell_value(row, header_mapping, 'fg', \"0\")\n",
    "            fga = get_cell_value(row, header_mapping, 'fga', \"0\")\n",
    "            tp = get_cell_value(row, header_mapping, 'fg3', \"0\")  # 3-pointers made\n",
    "            tpa = get_cell_value(row, header_mapping, 'fg3a', \"0\")  # 3-point attempts\n",
    "            ft = get_cell_value(row, header_mapping, 'ft', \"0\")  # Free throws made\n",
    "            fta = get_cell_value(row, header_mapping, 'fta', \"0\")  # Free throw attempts\n",
    "            pts = get_cell_value(row, header_mapping, 'pts', \"0\")  # Points\n",
    "        else:\n",
    "            # Per possession stats use _per_poss suffix\n",
    "            fg = get_cell_value(row, header_mapping, 'fg_per_poss', \"0\")\n",
    "            fga = get_cell_value(row, header_mapping, 'fga_per_poss', \"0\")\n",
    "            tp = get_cell_value(row, header_mapping, 'fg3_per_poss', \"0\")\n",
    "            tpa = get_cell_value(row, header_mapping, 'fg3a_per_poss', \"0\")\n",
    "            ft = get_cell_value(row, header_mapping, 'ft_per_poss', \"0\")\n",
    "            fta = get_cell_value(row, header_mapping, 'fta_per_poss', \"0\")\n",
    "            pts = get_cell_value(row, header_mapping, 'pts_per_poss', \"0\")\n",
    "\n",
    "        data.append([\n",
    "            player_name, player_url, team_acronym, config.CURRENT_YEAR, \n",
    "            gp, mp, fga, fg, tpa, tp, fta, ft, pts\n",
    "        ])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    year_data = pd.DataFrame(\n",
    "        data=data, \n",
    "        columns=['player', 'url', 'team', 'year', 'G', 'MP', 'FGA', 'FG', '3PA', '3P', 'FTA', 'FT', 'PTS']\n",
    "    )\n",
    "    \n",
    "    if not year_data.empty:\n",
    "        print(f\"Successfully processed {len(year_data)} players for {config.CURRENT_YEAR} ({data_type})\")\n",
    "        if len(year_data) > 0:\n",
    "            print(f\"Sample player: {year_data.iloc[0]['player']} - {year_data.iloc[0]['team']}\")\n",
    "    else:\n",
    "        print(f\"WARNING: No data found for {config.CURRENT_YEAR}\")\n",
    "    \n",
    "    frames.append(year_data)\n",
    "    time.sleep(2)  # Be nice to the server\n",
    "    \n",
    "    return pd.concat(frames) if frames else pd.DataFrame()\n",
    "\n",
    "def process_player_ids(df, master_df):\n",
    "    \"\"\"Process player IDs using master dataframe and NBA API\"\"\"\n",
    "    print(f\"Processing player IDs for {len(df)} players\")\n",
    "    \n",
    "    # Extract Basketball Reference IDs\n",
    "    df['bref_id'] = df['url'].str.split('/', expand=True)[5].str.split('.', expand=True)[0]\n",
    "    \n",
    "    # Create ID mapping dictionary from master\n",
    "    match_dict = dict(zip(master_df['bref_id'], master_df['nba_id']))\n",
    "    team_dict = dict(zip(master_df['team'], master_df['team_id']))\n",
    "    \n",
    "    # Add hardcoded IDs\n",
    "    match_dict.update(config.SEARCH_DICT)\n",
    "    \n",
    "    # Map IDs to dataframe\n",
    "    df['nba_id'] = df['bref_id'].map(match_dict)\n",
    "    \n",
    "    # Find missing IDs\n",
    "    missing_ids = df[df['nba_id'].isna()].reset_index(drop=True)\n",
    "    missing_count = len(missing_ids)\n",
    "    print(f\"Found {missing_count} players without NBA IDs\")\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        # Try to find IDs using NBA API\n",
    "        print(\"Fetching player data from NBA API...\")\n",
    "        try:\n",
    "            players_data = commonallplayers.CommonAllPlayers(\n",
    "                is_only_current_season=1, \n",
    "                season=config.CURRENT_SEASON\n",
    "            )\n",
    "            players_list = players_data.get_data_frames()[0]\n",
    "            player_names = dict(zip(players_list['DISPLAY_FIRST_LAST'], players_list['PERSON_ID']))\n",
    "            \n",
    "            # Map missing IDs\n",
    "            missing_ids['nba_id'] = missing_ids['player'].map(player_names)\n",
    "            found_count = missing_ids['nba_id'].notna().sum()\n",
    "            print(f\"Found {found_count} additional IDs from the NBA API\")\n",
    "            \n",
    "            # Add found players back to dataframe\n",
    "            if found_count > 0:\n",
    "                missing_ids_found = missing_ids[missing_ids['nba_id'].notna()]\n",
    "                df = pd.concat([df.dropna(subset=['nba_id']), missing_ids_found])\n",
    "                print(f\"Added {len(missing_ids_found)} players with newly found IDs\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Failed to fetch data from NBA API: {e}\")\n",
    "    \n",
    "    # Map team IDs\n",
    "    df['team_id'] = df['team'].map(team_dict)\n",
    "    \n",
    "    # Count final results\n",
    "    missing_final = df['nba_id'].isna().sum()\n",
    "    print(f\"Final count: {len(df) - missing_final} players with IDs, {missing_final} still missing\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_true_shooting(df):\n",
    "    \"\"\"Calculate True Shooting Percentage\"\"\"\n",
    "    print(\"Calculating True Shooting Percentage\")\n",
    "    \n",
    "    # Clean numeric columns\n",
    "    numeric_cols = ['FTA', 'FGA', 'PTS', 'G', 'MP']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].replace('', '0')\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Calculate TS%\n",
    "    df['TS%'] = (df['PTS'] / (2 * (df['FGA'] + 0.44 * df['FTA']))) * 100\n",
    "    \n",
    "    # Clean up extreme values\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df.loc[df['TS%'] > 150, 'TS%'] = 0\n",
    "    \n",
    "    print(f\"TS% stats: Min={df['TS%'].min():.2f}, Max={df['TS%'].max():.2f}, Avg={df['TS%'].mean():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def update_master_index(index_df, master_df):\n",
    "    \"\"\"Update master index with new players\"\"\"\n",
    "    print(f\"Updating master index\")\n",
    "    \n",
    "    # Create copy of current data\n",
    "    index_copy = index_df[['player', 'url', 'year', 'team', 'bref_id', 'nba_id', 'team_id']]\n",
    "    # Create copy of current data\n",
    "    index_copy = index_df[['player', 'url', 'year', 'team', 'bref_id', 'nba_id', 'team_id']]\n",
    "\n",
    "    # Print data types\n",
    "    print(index_copy.dtypes)\n",
    "\n",
    "    # Remove current year data from master\n",
    "    master_df = master_df[master_df.year != config.CURRENT_YEAR]\n",
    "    \n",
    "    # Concatenate and deduplicate\n",
    "    updated_master = pd.concat([master_df, index_copy])\n",
    "    updated_master.drop_duplicates(inplace=True)\n",
    "    nan_rows = updated_master[updated_master['nba_id'].isna()]\n",
    "    print(nan_rows)\n",
    "    updated_master['nba_id'] = updated_master['nba_id'].astype('int64')\n",
    "\n",
    "    \n",
    "    # Save updated master\n",
    "    updated_master['team_id']=updated_master['team_id'].astype(int)\n",
    "    #updated_master['nba_id']=updated_master['nba_id'].astype(int)\n",
    "    updated_master['year']=updated_master['year'].astype(int)\n",
    "\n",
    "    updated_master.to_csv(config.index_master_path, index=False)\n",
    "    updated_master.to_csv(config.index_master_path, index=False)\n",
    "\n",
    "    \n",
    "    print(f\"Master index updated: {len(updated_master)} total players\")\n",
    "    new_players = len(index_copy[~index_copy['bref_id'].isin(master_df['bref_id'])])\n",
    "    print(f\"Added {new_players} new players to the index\")\n",
    "    \n",
    "    return updated_master\n",
    "\n",
    "def update_stats_file(index_df, stats_type):\n",
    "    \"\"\"Update either totals or scoring stats file\"\"\"\n",
    "    print(f\"Updating {stats_type} stats file\")\n",
    "    \n",
    "    # Set file path based on stats type\n",
    "    if stats_type == 'totals':\n",
    "        file_path = config.totals_path\n",
    "        columns = ['player', 'TS%', 'PTS', 'MP', 'team', 'G', 'FTA', 'FGA', 'year', 'nba_id']\n",
    "    else:  # scoring\n",
    "        file_path = config.scoring_path\n",
    "        columns = ['player', 'TS%', 'PTS', 'MP', 'team', 'G', 'year', 'nba_id']\n",
    "    \n",
    "    # Read existing data\n",
    "    try:\n",
    "        old_stats = pd.read_csv(file_path)\n",
    "        old_stats = old_stats[old_stats.year < config.CURRENT_YEAR]\n",
    "        print(f\"Read {len(old_stats)} existing stat entries from {file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No existing stats file found at {file_path}, creating new file\")\n",
    "        old_stats = pd.DataFrame()\n",
    "    \n",
    "    # Select required columns\n",
    "    new_df = index_df[columns].copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    new_df = new_df.rename(columns={\n",
    "        'player': 'Player',\n",
    "        'team': 'Tm'\n",
    "    })\n",
    "    \n",
    "    # Combine old and new data\n",
    "    new_stats = pd.concat([old_stats, new_df])\n",
    "    \n",
    "    # Final cleanup\n",
    "    new_stats.fillna(0, inplace=True)\n",
    "    new_stats.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    new_stats.loc[new_stats['TS%'] > 150, 'TS%'] = 0\n",
    "    \n",
    "    # Save updated stats\n",
    "    new_stats.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"Updated {stats_type} stats: {len(new_df)} new entries, {len(new_stats)} total entries\")\n",
    "    \n",
    "    return new_stats\n",
    "\n",
    "def export_games_data(scoring_df, playoffs=False):\n",
    "    \"\"\"Export games played data for other parts of the application\"\"\"\n",
    "    gp = scoring_df[['nba_id', 'Player', 'year', 'G']].reset_index()\n",
    "    \n",
    "    if playoffs:\n",
    "        output_path = '../player_sheets/lineups/ps_games.csv'\n",
    "        extra_path = '../extra_data/wowy_leverage/ps_games.csv'\n",
    "        gp.to_csv(output_path, index=False)\n",
    "        gp.to_csv(extra_path, index=False)\n",
    "        print(f\"Exported playoffs games data to {output_path} and {extra_path}\")\n",
    "    else:\n",
    "        output_path = '../player_sheets/lineups/games.csv'\n",
    "        gp.to_csv(output_path, index=False)\n",
    "        print(f\"Exported regular season games data to {output_path}\")\n",
    "    \n",
    "    print(f\"Games data exported: {len(gp)} player entries\")\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"NBA Data Scraper - {config.CURRENT_SEASON} {'Playoffs' if config.PLAYOFFS_MODE else 'Regular Season'}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Load master index\n",
    "    try:\n",
    "        master = pd.read_csv(config.index_master_path)\n",
    "        print(f\"Loaded master index with {len(master)} entries\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No master index found, creating a new one\")\n",
    "        master = pd.DataFrame(columns=['player', 'url', 'year', 'team', 'bref_id', 'nba_id', 'team_id'])\n",
    "    \n",
    "    # Step 2: Get totals data\n",
    "    print(\"\\n--- Processing Totals Data ---\")\n",
    "    totals_frame = pull_bref_data(totals=True)\n",
    "    if not totals_frame.empty:\n",
    "        totals_frame = process_player_ids(totals_frame, master)\n",
    "        totals_frame = calculate_true_shooting(totals_frame)\n",
    "        master = update_master_index(totals_frame, master)\n",
    "        update_stats_file(totals_frame, 'totals')\n",
    "    \n",
    "    # Step 3: Get per possession data\n",
    "    print(\"\\n--- Processing Per Possession Data ---\")\n",
    "    scoring_frame = pull_bref_data(totals=False)\n",
    "    if not scoring_frame.empty:\n",
    "        scoring_frame = process_player_ids(scoring_frame, master)\n",
    "        scoring_frame = calculate_true_shooting(scoring_frame)\n",
    "        update_stats_file(scoring_frame, 'scoring')\n",
    "    \n",
    "    # Step 4: Export games data\n",
    "    print(\"\\n--- Exporting Games Data ---\")\n",
    "    try:\n",
    "        scoring = pd.read_csv(config.scoring_path)\n",
    "        export_games_data(scoring, playoffs=config.PLAYOFFS_MODE)\n",
    "        \n",
    "        if not config.PLAYOFFS_MODE:\n",
    "            # Also export playoff games data if in regular season mode\n",
    "            try:\n",
    "                ps_scoring = pd.read_csv('scoring_ps.csv')\n",
    "                export_games_data(ps_scoring, playoffs=True)\n",
    "            except FileNotFoundError:\n",
    "                print(\"No playoffs scoring data found, skipping playoffs games export\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No scoring data found at {config.scoring_path}, skipping games export\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Scraping process completed successfully!\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
