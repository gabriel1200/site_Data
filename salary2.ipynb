{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fd31ce-a327-414e-86c9-0f83209c9d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting salary data for ATL\n",
      "Getting salary data for BOS\n",
      "Getting salary data for BKN\n",
      "Getting salary data for CHA\n",
      "Getting salary data for CHI\n",
      "Getting salary data for CLE\n",
      "Getting salary data for DAL\n",
      "Getting salary data for DEN\n",
      "Getting salary data for DET\n",
      "Getting salary data for GSW\n",
      "Getting salary data for HOU\n",
      "Getting salary data for IND\n",
      "Getting salary data for LAC\n",
      "Getting salary data for LAL\n",
      "Getting salary data for MEM\n",
      "Getting salary data for MIA\n",
      "Getting salary data for MIL\n",
      "Getting salary data for MIN\n",
      "Getting salary data for NOP\n",
      "Getting salary data for NYK\n",
      "Getting salary data for OKC\n",
      "Getting salary data for ORL\n",
      "Getting salary data for PHI\n",
      "Getting salary data for PHX\n",
      "Getting salary data for POR\n",
      "Getting salary data for SAC\n",
      "Getting salary data for SAS\n",
      "Getting salary data for TOR\n",
      "Getting salary data for UTA\n",
      "Getting salary data for WAS\n"
     ]
    }
   ],
   "source": [
    "# Populate the new DataFrame with player options and team options\n",
    "import pandas as pd\n",
    "import math\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def team_books(team):\n",
    "    print(f\"Getting salary data for {team}\")\n",
    "    \n",
    "    nba_team_urls = {\n",
    "        \"ATL\": \"https://www.spotrac.com/nba/atlanta-hawks/yearly\",\n",
    "        \"BOS\": \"https://www.spotrac.com/nba/boston-celtics/yearly\",\n",
    "        \"BKN\": \"https://www.spotrac.com/nba/brooklyn-nets/yearly\",\n",
    "        \"CHA\": \"https://www.spotrac.com/nba/charlotte-hornets/yearly\",\n",
    "        \"CHI\": \"https://www.spotrac.com/nba/chicago-bulls/yearly\",\n",
    "        \"CLE\": \"https://www.spotrac.com/nba/cleveland-cavaliers/yearly\",\n",
    "        \"DAL\": \"https://www.spotrac.com/nba/dallas-mavericks/yearly\",\n",
    "        \"DEN\": \"https://www.spotrac.com/nba/denver-nuggets/yearly\",\n",
    "        \"DET\": \"https://www.spotrac.com/nba/detroit-pistons/yearly\",\n",
    "        \"GSW\": \"https://www.spotrac.com/nba/golden-state-warriors/yearly\",\n",
    "        \"HOU\": \"https://www.spotrac.com/nba/houston-rockets/yearly\",\n",
    "        \"IND\": \"https://www.spotrac.com/nba/indiana-pacers/yearly\",\n",
    "        \"LAC\": \"https://www.spotrac.com/nba/la-clippers/yearly\",\n",
    "        \"LAL\": \"https://www.spotrac.com/nba/los-angeles-lakers/yearly\",\n",
    "        \"MEM\": \"https://www.spotrac.com/nba/memphis-grizzlies/yearly\",\n",
    "        \"MIA\": \"https://www.spotrac.com/nba/miami-heat/yearly\",\n",
    "        \"MIL\": \"https://www.spotrac.com/nba/milwaukee-bucks/yearly\",\n",
    "        \"MIN\": \"https://www.spotrac.com/nba/minnesota-timberwolves/yearly\",\n",
    "        \"NOP\": \"https://www.spotrac.com/nba/new-orleans-pelicans/yearly\",\n",
    "        \"NYK\": \"https://www.spotrac.com/nba/new-york-knicks/yearly\",\n",
    "        \"OKC\": \"https://www.spotrac.com/nba/oklahoma-city-thunder/yearly\",\n",
    "        \"ORL\": \"https://www.spotrac.com/nba/orlando-magic/yearly\",\n",
    "        \"PHI\": \"https://www.spotrac.com/nba/philadelphia-76ers/yearly\",\n",
    "        \"PHX\": \"https://www.spotrac.com/nba/phoenix-suns/yearly\",\n",
    "        \"POR\": \"https://www.spotrac.com/nba/portland-trail-blazers/yearly\",\n",
    "        \"SAC\": \"https://www.spotrac.com/nba/sacramento-kings/yearly\",\n",
    "        \"SAS\": \"https://www.spotrac.com/nba/san-antonio-spurs/yearly\",\n",
    "        \"TOR\": \"https://www.spotrac.com/nba/toronto-raptors/yearly\",\n",
    "        \"UTA\": \"https://www.spotrac.com/nba/utah-jazz/yearly\",\n",
    "        \"WAS\": \"https://www.spotrac.com/nba/washington-wizards/yearly\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    url = nba_team_urls[team.upper()]\n",
    "    \n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all table bodies\n",
    "    tbodies = soup.find_all('tbody')\n",
    "    \n",
    "    # Lists to store link data\n",
    "    texts = []\n",
    "    hrefs = []\n",
    "    \n",
    "    # Process each tbody\n",
    "    for tbody in tbodies:\n",
    "        # Find all td elements that contain links\n",
    "        td_with_links = tbody.find_all('td')\n",
    "        \n",
    "        for td in td_with_links:\n",
    "            # Find all anchor tags within the td\n",
    "            links = td.find_all('a')\n",
    "            \n",
    "            # Extract hrefs from the links\n",
    "            for link in links:\n",
    "                href = link.get('href')\n",
    "                if href and href != 'javascript:void(0)':  # Only add valid links\n",
    "                    texts.append(link.text.strip())\n",
    "                    hrefs.append(href)\n",
    "    \n",
    "    # Create DataFrame from the collected data\n",
    "    links_df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'href': hrefs\n",
    "    })\n",
    "    \n",
    "    # Get the original table data as well\n",
    "    tables_df= pd.read_html(url)\n",
    "    links_df.rename(columns={'text':'name','href':'url'},inplace=True)\n",
    "\n",
    "    links_df['id']=links_df['url'].str.split('id/').str[-1]\n",
    "    \n",
    "    return links_df\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Display the links DataFrame\n",
    "teams = ['ATL', 'BOS', 'BKN', 'CHA', 'CHI', 'CLE', 'DAL', 'DEN', 'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI', 'PHX', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS']\n",
    "\n",
    "salary_frames=[]\n",
    "for team in teams:\n",
    "    frame=team_books(team)\n",
    "    frame['team']=team\n",
    "    salary_frames.append(frame)\n",
    "    \n",
    "\n",
    "salary_master=pd.concat(salary_frames)\n",
    "salary_master.to_csv('salary_id.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465a87f5-0a2f-43c0-a55a-641476317eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>id</th>\n",
       "      <th>team</th>\n",
       "      <th>nba_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bogdan Bogdanovic</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/15379</td>\n",
       "      <td>15379</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Nikola Djurisic</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/92954</td>\n",
       "      <td>92954</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Marcus Eriksson</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/17878</td>\n",
       "      <td>17878</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Alain Digbeu</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/82260</td>\n",
       "      <td>82260</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Augusto Binelli</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/82259</td>\n",
       "      <td>82259</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>Peter Fehse</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/82258</td>\n",
       "      <td>82258</td>\n",
       "      <td>UTA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>Jonas Valanciunas</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/8055</td>\n",
       "      <td>8055</td>\n",
       "      <td>WAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Bub Carrington</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/91766</td>\n",
       "      <td>91766</td>\n",
       "      <td>WAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Tomas Satoransky</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/10857</td>\n",
       "      <td>10857</td>\n",
       "      <td>WAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Yannick Nzosa</td>\n",
       "      <td>https://www.spotrac.com/nba/player/_/id/78164</td>\n",
       "      <td>78164</td>\n",
       "      <td>WAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                            url     id  \\\n",
       "3     Bogdan Bogdanovic  https://www.spotrac.com/nba/player/_/id/15379  15379   \n",
       "52      Nikola Djurisic  https://www.spotrac.com/nba/player/_/id/92954  92954   \n",
       "53      Marcus Eriksson  https://www.spotrac.com/nba/player/_/id/17878  17878   \n",
       "54         Alain Digbeu  https://www.spotrac.com/nba/player/_/id/82260  82260   \n",
       "55      Augusto Binelli  https://www.spotrac.com/nba/player/_/id/82259  82259   \n",
       "...                 ...                                            ...    ...   \n",
       "1486        Peter Fehse  https://www.spotrac.com/nba/player/_/id/82258  82258   \n",
       "1493  Jonas Valanciunas   https://www.spotrac.com/nba/player/_/id/8055   8055   \n",
       "1498     Bub Carrington  https://www.spotrac.com/nba/player/_/id/91766  91766   \n",
       "1510   Tomas Satoransky  https://www.spotrac.com/nba/player/_/id/10857  10857   \n",
       "1547      Yannick Nzosa  https://www.spotrac.com/nba/player/_/id/78164  78164   \n",
       "\n",
       "     team  nba_id  \n",
       "3     ATL     NaN  \n",
       "52    ATL     NaN  \n",
       "53    ATL     NaN  \n",
       "54    ATL     NaN  \n",
       "55    ATL     NaN  \n",
       "...   ...     ...  \n",
       "1486  UTA     NaN  \n",
       "1493  WAS     NaN  \n",
       "1498  WAS     NaN  \n",
       "1510  WAS     NaN  \n",
       "1547  WAS     NaN  \n",
       "\n",
       "[170 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_master=pd.read_csv('salary_id.csv')\n",
    "salary_master.drop_duplicates(inplace=True)\n",
    "print(len(salary_master))\n",
    "index=pd.read_csv('index_master.csv')\n",
    "\n",
    "index=index[index.year>2010]\n",
    "\n",
    "mydict=dict(zip(index['player'].str.lower(),index['nba_id']))\n",
    "\n",
    "salary_master['nba_id']=salary_master['name'].str.lower().map(mydict)\n",
    "salary_master\n",
    "\n",
    "\n",
    "salary_master[salary_master.nba_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c316f00c-eb65-4860-9319-e82b82e7ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel1200/.local/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unmatched names: 161\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "\n",
    "def match_names(salary_df, index_df, threshold=85):\n",
    "    \"\"\"\n",
    "    Match names between two dataframes using fuzzy string matching.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    salary_df : DataFrame\n",
    "        DataFrame containing salary information with 'name' column\n",
    "    index_df : DataFrame\n",
    "        DataFrame containing index information with 'player' and 'nba_id' columns\n",
    "    threshold : int\n",
    "        Minimum similarity score (0-100) required for a match\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Original salary DataFrame with matched nba_ids\n",
    "    dict\n",
    "        Dictionary of name mappings for manual verification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create clean versions of names for matching\n",
    "    def clean_name(name):\n",
    "        # Convert to lowercase and remove accents\n",
    "        return unidecode(str(name).lower().strip())\n",
    "    \n",
    "    # Clean names in both dataframes\n",
    "    salary_names = salary_df['name'].apply(clean_name)\n",
    "    index_names = index_df['player'].apply(clean_name)\n",
    "    \n",
    "    # Create dictionary for exact matches first\n",
    "    exact_matches = dict(zip(index_names, index_df['nba_id']))\n",
    "    \n",
    "    # Initialize results\n",
    "    matched_ids = []\n",
    "    name_mappings = {}\n",
    "    \n",
    "    # For each salary name, find the best match\n",
    "    for salary_name in salary_names:\n",
    "        # Try exact match first\n",
    "        if salary_name in exact_matches:\n",
    "            matched_ids.append(exact_matches[salary_name])\n",
    "            continue\n",
    "            \n",
    "        # If no exact match, try fuzzy matching\n",
    "        max_score = 0\n",
    "        best_match = None\n",
    "        best_id = None\n",
    "        \n",
    "        for idx_name, nba_id in zip(index_names, index_df['nba_id']):\n",
    "            # Calculate similarity score\n",
    "            score = fuzz.ratio(salary_name, idx_name)\n",
    "            \n",
    "            # Update best match if score is higher\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_match = idx_name\n",
    "                best_id = nba_id\n",
    "        \n",
    "        # If we found a good match\n",
    "        if max_score >= threshold:\n",
    "            matched_ids.append(best_id)\n",
    "            name_mappings[salary_name] = {\n",
    "                'matched_to': best_match,\n",
    "                'score': max_score,\n",
    "                'nba_id': best_id\n",
    "            }\n",
    "        else:\n",
    "            matched_ids.append(None)\n",
    "            name_mappings[salary_name] = {\n",
    "                'matched_to': None,\n",
    "                'score': None,\n",
    "                'nba_id': None\n",
    "            }\n",
    "    \n",
    "    # Create new dataframe with matches\n",
    "    result_df = salary_df.copy()\n",
    "    result_df['nba_id'] = matched_ids\n",
    "    \n",
    "    return result_df, name_mappings\n",
    "\n",
    "# Example usage:\n",
    "# First, install required packages:\n",
    "# pip install fuzzywuzzy python-Levenshtein unidecode\n",
    "\n",
    "salary_master = pd.read_csv('salary_id.csv')\n",
    "index = pd.read_csv('index_master.csv')\n",
    "index = index[index.year > 2016]\n",
    "\n",
    "# Match names\n",
    "matched_df, mappings = match_names(salary_master, index)\n",
    "\n",
    "# Show unmatched names\n",
    "unmatched = matched_df[matched_df.nba_id.isna()]\n",
    "print(f\"Total unmatched names: {len(unmatched)}\")\n",
    "\n",
    "# Show some example mappings for verification\n",
    "problematic_matches = {\n",
    "    name: info for name, info in mappings.items() \n",
    "    if info['score'] is not None and info['score'] < 95\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184e033f-ef84-4c89-9e2b-84e0e8cef2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c2efcc-bb78-485f-9f76-1b9fe7fd50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmatched=matched_df[matched_df.nba_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b93f1b-0141-4bed-b3f6-112e3fd97762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: Mohamed Bamba\n",
      "NBA ID: 1628964\n",
      "---\n",
      "Player: Cameron Thomas\n",
      "NBA ID: 1630560\n",
      "---\n",
      "Player: Nah'Shon Hyland\n",
      "NBA ID: 1630538\n",
      "---\n",
      "Player: Sviatoslav Mykhailiuk\n",
      "NBA ID: 1629004\n",
      "---\n",
      "Player: Nikola Topic\n",
      "NBA ID: 1642260\n",
      "---\n",
      "Player: DaRon Holmes II\n",
      "NBA ID: 1641747\n",
      "---\n",
      "Player: G.G. Jackson\n",
      "NBA ID: 1641713\n",
      "---\n",
      "\n",
      "Remaining unmatched players:\n",
      "62          Keion Brooks Jr.\n",
      "338        Kenyon Martin Jr.\n",
      "65        Kevin McCullar Jr.\n",
      "325     Terrence Shannon Jr.\n",
      "81              Anton Watson\n",
      "64                  Boo Buie\n",
      "273           Bub Carrington\n",
      "37            Emanuel Miller\n",
      "14            Isaiah Stevens\n",
      "35              Jackson Rowe\n",
      "36              N'Faly Dante\n",
      "33            Tolu Smith III\n",
      "230      V  Ricky Council IV\n",
      "0                Zyon Pullin\n",
      "Name: Player, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def standardize_names(df, name_column):\n",
    "    \"\"\"\n",
    "    Standardizes player names with enhanced handling of special cases.\n",
    "    \"\"\"\n",
    "    def clean_name(name):\n",
    "        # Initial cleanup\n",
    "        name = str(name).strip()\n",
    "        \n",
    "        # Fix specific formatting issues\n",
    "        name_fixes = {\n",
    "            'ilva  Tristan Da Silva': 'Tristan Da Silva',\n",
    "            'r  Brandon Boston Jr': 'Brandon Boston Jr.',\n",
    "            'Bub Carrington': 'Ja\\'Von Carrington',\n",
    "            'G.G. Jackson': 'Gregory Jackson II',\n",
    "            'Nah\\'Shon Hyland': 'Bones Hyland',\n",
    "            'Sviatoslav Mykhailiuk': 'Svi Mykhailiuk',\n",
    "            'N\\'Faly Dante': 'NFaly Dante'  # Remove apostrophe\n",
    "        }\n",
    "        \n",
    "        if name in name_fixes:\n",
    "            return name_fixes[name]\n",
    "            \n",
    "        # Handle suffixes consistently\n",
    "        suffix_map = {\n",
    "            r'Jr\\.?$': 'Jr.',  # Standardize Jr. suffix\n",
    "            r'Sr\\.?$': 'Sr.',  # Standardize Sr. suffix\n",
    "            r'III$': 'III',    # Keep III\n",
    "            r'II$': 'II',      # Keep II\n",
    "            r'IV$': 'IV',      # Keep IV\n",
    "            r'V$': 'V'         # Keep V\n",
    "        }\n",
    "        \n",
    "        # Apply suffix standardization\n",
    "        cleaned_name = name\n",
    "        for pattern, replacement in suffix_map.items():\n",
    "            if re.search(pattern, cleaned_name, flags=re.IGNORECASE):\n",
    "                # Remove the suffix first\n",
    "                base_name = re.sub(pattern, '', cleaned_name, flags=re.IGNORECASE).strip()\n",
    "                # Add back the standardized suffix\n",
    "                cleaned_name = f\"{base_name} {replacement}\"\n",
    "        \n",
    "        # Clean up extra spaces\n",
    "        cleaned_name = ' '.join(cleaned_name.split())\n",
    "        \n",
    "        return cleaned_name\n",
    "    \n",
    "    # Create a copy of the dataframe\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Store original names and create standardized versions\n",
    "    result_df['original_name'] = result_df[name_column]\n",
    "    result_df['standardized_name'] = result_df[name_column].apply(clean_name)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Apply the enhanced standardization\n",
    "\n",
    "salary=pd.read_csv('salary.csv')\n",
    "matched_df['Player']=matched_df['name']\n",
    "salary_standardized = standardize_names(salary, 'Player')\n",
    "matched_df_standardized = standardize_names(matched_df, 'Player')\n",
    "\n",
    "# Merge using standardized names\n",
    "merged = salary_standardized.merge(\n",
    "    matched_df_standardized,\n",
    "    left_on='standardized_name',\n",
    "    right_on='standardized_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Clean up the merged dataframe\n",
    "merged = merged.drop(['Player_y', 'standardized_name'], axis=1)\n",
    "merged = merged.rename(columns={\n",
    "    'original_name_x': 'Player',\n",
    "    'original_name_y': 'matched_name'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "nba_ids = {\n",
    "    'Mohamed Bamba': '1628964',\n",
    "    'Cameron Thomas': '1630560',\n",
    "    \"Nah'Shon Hyland\": '1630538',\n",
    "    'Sviatoslav Mykhailiuk': '1629004',\n",
    "    'Kenyon Martin Jr.': '1630231',\n",
    "    'Nikola Topic':'1642260',\n",
    "\n",
    "    'DaRon Holmes II':'1641747',\n",
    "     'G.G. Jackson':'1641713'\n",
    "\n",
    "}\n",
    "# Check remaining unmatched players\n",
    "unmatched = merged[merged['nba_id'].isna()]\n",
    "def map_additional_ids(df, id_mapping):\n",
    "    \"\"\"\n",
    "    Maps additional NBA IDs to players in the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame containing player information\n",
    "    id_mapping : dict\n",
    "        Dictionary mapping player names to NBA IDs\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Updated DataFrame with mapped NBA IDs\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # For each player in the mapping\n",
    "    for player, nba_id in id_mapping.items():\n",
    "        # Update the nba_id where the player name matches\n",
    "        mask = result_df['Player'] == player\n",
    "        result_df.loc[mask, 'nba_id'] = nba_id\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Apply the mapping\n",
    "merged = map_additional_ids(merged, nba_ids)\n",
    "\n",
    "# Verify the updates\n",
    "for player in nba_ids.keys():\n",
    "    player_row = merged[merged['Player'] == player]\n",
    "    if not player_row.empty:\n",
    "        print(f\"Player: {player}\")\n",
    "        print(f\"NBA ID: {player_row['nba_id'].iloc[0]}\")\n",
    "        print(\"---\")\n",
    "\n",
    "# Show remaining unmatched players\n",
    "unmatched = merged[merged['nba_id'].isna()]\n",
    "print(\"\\nRemaining unmatched players:\")\n",
    "print(unmatched['Player'].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d232a1-29ef-4817-b057-c75448c2cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(columns='Player_x',inplace=True)\n",
    "merged.to_csv('salary_spread.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4cf2b-888d-42f9-bd8d-a256cb6a7304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b468a95-8c75-4737-88fc-ef1e007a43b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
