{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fe7ac-1455-4b6e-a21d-ddd7b1dbd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Constants\n",
    "NBA_TEAM_URLS ={\n",
    "        \"ATL\": \"https://www.spotrac.com/nba/atlanta-hawks/yearly\",\n",
    "        \"BOS\": \"https://www.spotrac.com/nba/boston-celtics/yearly\",\n",
    "        \"BKN\": \"https://www.spotrac.com/nba/brooklyn-nets/yearly\",\n",
    "        \"CHA\": \"https://www.spotrac.com/nba/charlotte-hornets/yearly\",\n",
    "        \"CHI\": \"https://www.spotrac.com/nba/chicago-bulls/yearly\",\n",
    "        \"CLE\": \"https://www.spotrac.com/nba/cleveland-cavaliers/yearly\",\n",
    "        \"DAL\": \"https://www.spotrac.com/nba/dallas-mavericks/yearly\",\n",
    "        \"DEN\": \"https://www.spotrac.com/nba/denver-nuggets/yearly\",\n",
    "        \"DET\": \"https://www.spotrac.com/nba/detroit-pistons/yearly\",\n",
    "        \"GSW\": \"https://www.spotrac.com/nba/golden-state-warriors/yearly\",\n",
    "        \"HOU\": \"https://www.spotrac.com/nba/houston-rockets/yearly\",\n",
    "        \"IND\": \"https://www.spotrac.com/nba/indiana-pacers/yearly\",\n",
    "        \"LAC\": \"https://www.spotrac.com/nba/la-clippers/yearly\",\n",
    "        \"LAL\": \"https://www.spotrac.com/nba/los-angeles-lakers/yearly\",\n",
    "        \"MEM\": \"https://www.spotrac.com/nba/memphis-grizzlies/yearly\",\n",
    "        \"MIA\": \"https://www.spotrac.com/nba/miami-heat/yearly\",\n",
    "        \"MIL\": \"https://www.spotrac.com/nba/milwaukee-bucks/yearly\",\n",
    "        \"MIN\": \"https://www.spotrac.com/nba/minnesota-timberwolves/yearly\",\n",
    "        \"NOP\": \"https://www.spotrac.com/nba/new-orleans-pelicans/yearly\",\n",
    "        \"NYK\": \"https://www.spotrac.com/nba/new-york-knicks/yearly\",\n",
    "        \"OKC\": \"https://www.spotrac.com/nba/oklahoma-city-thunder/yearly\",\n",
    "        \"ORL\": \"https://www.spotrac.com/nba/orlando-magic/yearly\",\n",
    "        \"PHI\": \"https://www.spotrac.com/nba/philadelphia-76ers/yearly\",\n",
    "        \"PHX\": \"https://www.spotrac.com/nba/phoenix-suns/yearly\",\n",
    "        \"POR\": \"https://www.spotrac.com/nba/portland-trail-blazers/yearly\",\n",
    "        \"SAC\": \"https://www.spotrac.com/nba/sacramento-kings/yearly\",\n",
    "        \"SAS\": \"https://www.spotrac.com/nba/san-antonio-spurs/yearly\",\n",
    "        \"TOR\": \"https://www.spotrac.com/nba/toronto-raptors/yearly\",\n",
    "        \"UTA\": \"https://www.spotrac.com/nba/utah-jazz/yearly\",\n",
    "        \"WAS\": \"https://www.spotrac.com/nba/washington-wizards/yearly\"\n",
    "    }\n",
    "\n",
    "SEASONS = ['2024-25', '2025-26', '2026-27', '2027-28', '2028-29']\n",
    "EXTRA_SEASONS = ['2029-30', '2030-31']\n",
    "FREE_AGENT_TYPES = ['UFA', 'RFA']\n",
    "\n",
    "def get_team_data(url: str, timeout: int = 10) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Safely fetch and parse HTML tables from the team URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        return pd.read_html(response.text)\n",
    "    except RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return []\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing HTML tables: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def clean_player_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean player names by removing suffixes and extra spaces.\n",
    "    \"\"\"\n",
    "    name = name.split(' ', 1)[1] if ' ' in name else name\n",
    "    return name.replace('III ', '').replace('II ', '').replace('r. ', '')\n",
    "\n",
    "def process_salary_value(value: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert salary strings to float values.\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or any(fa_type in str(value) for fa_type in FREE_AGENT_TYPES):\n",
    "        return 0.0\n",
    "    \n",
    "    value = str(value).replace('Ext. Elig.', '').strip()\n",
    "    value = ''.join(filter(str.isdigit, value))\n",
    "    return float(value) if value else 0.0\n",
    "\n",
    "def process_option_type(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Determine the type of contract option.\n",
    "    \"\"\"\n",
    "    option_type = row['Type']\n",
    "    if 'PLAYER' in option_type:\n",
    "        return 'P'\n",
    "    elif 'CLUB' in option_type:\n",
    "        return 'T'\n",
    "    elif 'GUARANTEED' in option_type:\n",
    "        return 'NG'\n",
    "    elif 'EXTENSION' in option_type:\n",
    "        return 'EE'\n",
    "    elif 'RFA' in option_type:\n",
    "        return 'RFA'\n",
    "    elif 'UNREST' in option_type:\n",
    "        return 'UFA'\n",
    "    else:\n",
    "        value = row['Value']\n",
    "        return f\"{option_type}{' ' + value if not pd.isna(value) else ''}\"\n",
    "\n",
    "def get_available_seasons(salary_df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get list of available seasons from salary data.\n",
    "    \"\"\"\n",
    "    available_seasons = SEASONS.copy()\n",
    "    for season in EXTRA_SEASONS:\n",
    "        if season in salary_df.columns:\n",
    "            available_seasons.append(season)\n",
    "    return available_seasons\n",
    "\n",
    "def process_cap_holds(df: pd.DataFrame, team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process cap holds table.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return pd.DataFrame()\n",
    "    df.columns = ['Player' if 'player' in col.lower() else col for col in df.columns]\n",
    "\n",
    "    # Rename columns if necessary\n",
    "    if 'Player' in df.columns:\n",
    "        df = df.copy()\n",
    "        \n",
    "        \n",
    "        # Clean player names\n",
    "        df['Player'] = df['Player'].apply(clean_player_name)\n",
    "        \n",
    "        # Process values\n",
    "        value_cols = [col for col in df.columns if col != 'Player']\n",
    "        for col in value_cols:\n",
    "            df[col] = df[col].apply(process_salary_value)\n",
    "        \n",
    "        df['Team'] = team\n",
    "        \n",
    "    return df\n",
    "\n",
    "def process_dead_money(df: pd.DataFrame, team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process dead money table.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = df.copy()\n",
    "    # Standardize column \n",
    "    df.columns = ['Player' if 'player' in col.lower() else col for col in df.columns]\n",
    "    if 'Player' in df.columns:\n",
    "        \n",
    "        \n",
    "        # Clean player names\n",
    "        df['Player'] = df['Player'].apply(clean_player_name)\n",
    "        \n",
    "        # Process values\n",
    "        value_cols = [col for col in df.columns if col != 'Player']\n",
    "        for col in value_cols:\n",
    "            df[col] = df[col].apply(process_salary_value)\n",
    "        \n",
    "        df['Team'] = team\n",
    "    return df\n",
    "\n",
    "def process_summary(df: pd.DataFrame, team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process summary table.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = df.copy()\n",
    "    # Process values and add team identifier\n",
    "    value_cols = df.columns\n",
    "    for col in value_cols:\n",
    "        df[col] = df[col].apply(process_salary_value)\n",
    "    \n",
    "    df['Team'] = team\n",
    "    return df\n",
    "\n",
    "def get_team_data(url: str, timeout: int = 10) -> Tuple[List[pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Fetch and parse HTML tables from the team URL, along with their section headers.\n",
    "    Returns tuple of (list of dataframes, list of headers)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all tables and their preceding h2 headers\n",
    "        tables_data = []\n",
    "        headers = []\n",
    "        \n",
    "        # Get all tables\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "        for table in tables:\n",
    "            # Look for the nearest preceding h2\n",
    "            header = None\n",
    "            prev_elem = table.find_previous('h2')\n",
    "            if prev_elem:\n",
    "                header = prev_elem.get_text(strip=True)\n",
    "            \n",
    "            # Parse table into DataFrame\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            tables_data.append(df)\n",
    "            headers.append(header)\n",
    "        \n",
    "        return tables_data, headers\n",
    "        \n",
    "    except RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return [], []\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing HTML tables: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def find_table_by_header(dfs: List[pd.DataFrame], headers: List[str], target_header: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Find a specific table by its h2 header text.\n",
    "    \"\"\"\n",
    "    for df, header in zip(dfs, headers):\n",
    "        if header and target_header.lower() in header.lower():\n",
    "            return df\n",
    "    return None\n",
    "\n",
    "def process_salary_data(df: pd.DataFrame, team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process and clean salary data.\n",
    "    \"\"\"\n",
    "    # Clean column names\n",
    "    df.columns = ['Player'] + [col for col in df.columns[1:]]\n",
    "    \n",
    "    # Clean player names\n",
    "    df['Player'] = df['Player'].apply(clean_player_name)\n",
    "    \n",
    "    # Process salary values\n",
    "    seasons = get_available_seasons(df)\n",
    "    for season in seasons:\n",
    "        df[season] = df[season].apply(process_salary_value)\n",
    "    \n",
    "    df['Team'] = team\n",
    "    return df\n",
    "\n",
    "def process_options_data(df: pd.DataFrame, salary_df: pd.DataFrame, team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process and clean options data.\n",
    "    \"\"\"\n",
    "    df.columns = ['Deadline Date', 'Player', 'Type', 'Value']\n",
    "    \n",
    "\n",
    "    \n",
    "    # Process options\n",
    "    players = salary_df['Player'].unique()\n",
    "    seasons = get_available_seasons(salary_df)\n",
    "    \n",
    "    data = []\n",
    "    for player in players:\n",
    "        player_data = df[df['Player'] == player]\n",
    "        row = {'Player': player}\n",
    "        \n",
    "        for season in seasons:\n",
    "            row[season] = 0\n",
    "            season_data = player_data[player_data['Type'].str.contains(season, na=False)]\n",
    "            if not season_data.empty:\n",
    "                row[season] = process_option_type(season_data.iloc[0])\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    options_df = pd.DataFrame(data, columns=['Player'] + seasons)\n",
    "    options_df = options_df.drop_duplicates().reset_index(drop=True)\n",
    "    options_df['Team'] = team\n",
    "    \n",
    "    return options_df\n",
    "def team_books(team: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get salary, options, cap holds, dead money, and summary data for a given team.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {team}...\")\n",
    "    \n",
    "    # Fetch data\n",
    "    url = NBA_TEAM_URLS.get(team.upper())\n",
    "    if not url:\n",
    "        raise ValueError(f\"Invalid team code: {team}\")\n",
    "    \n",
    "    dfs, headers = get_team_data(url)\n",
    "    if not dfs:\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Find all relevant tables by their h2 headers\n",
    "    salary_df = find_table_by_header(dfs, headers, \"Active Roster\")  # or whatever the actual header text is\n",
    "    options_df = next((df for df in dfs if 'Deadline Date' in df.columns), None)\n",
    "\n",
    "    cap_holds_df = find_table_by_header(dfs, headers, \"Cap Hold\")\n",
    "\n",
    "    dead_money_df = find_table_by_header(dfs, headers, \"Dead Money\")\n",
    "\n",
    "    \n",
    "    summary_df = find_table_by_header(dfs, headers, \"Summary\")\n",
    "    if salary_df is None:\n",
    "        print(f\"Required salary table not found for {team}\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Process all tables\n",
    "    salary_df = process_salary_data(salary_df, team)\n",
    "    options_df = process_options_data(options_df, salary_df, team) if options_df is not None else pd.DataFrame()\n",
    "    cap_holds_df = process_cap_holds(cap_holds_df, team)\n",
    "    dead_money_df = process_dead_money(dead_money_df, team)\n",
    "    summary_df = process_summary(summary_df, team)\n",
    "    dead_money_df['Team']=team\n",
    "    cap_holds_df['Team']=team\n",
    "    summary_df['Team']=team\n",
    "\n",
    "    return salary_df, options_df, cap_holds_df, dead_money_df, summary_df\n",
    "\n",
    "def scrape_all_teams(teams: List[str], delay: float = 1.0) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Scrape data for all teams with rate limiting.\n",
    "    \"\"\"\n",
    "    salary_dfs = []\n",
    "    options_dfs = []\n",
    "    cap_holds_dfs = []\n",
    "    dead_money_dfs = []\n",
    "    summary_dfs = []\n",
    "    \n",
    "    for team in teams:\n",
    "        try:\n",
    "            salary_df, options_df, cap_holds_df, dead_money_df, summary_df = team_books(team)\n",
    "            \n",
    "            if not salary_df.empty:\n",
    "                salary_dfs.append(salary_df)\n",
    "            if not options_df.empty:\n",
    "                options_dfs.append(options_df)\n",
    "            if not cap_holds_df.empty:\n",
    "                cap_holds_dfs.append(cap_holds_df)\n",
    "            if not dead_money_df.empty:\n",
    "                dead_money_dfs.append(dead_money_df)\n",
    "            if not summary_df.empty:\n",
    "                summary_dfs.append(summary_df)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {team}: {e}\")\n",
    "        \n",
    "        time.sleep(delay)  # Rate limiting\n",
    "    \n",
    "    return (\n",
    "        pd.concat(salary_dfs) if salary_dfs else pd.DataFrame(),\n",
    "        pd.concat(options_dfs) if options_dfs else pd.DataFrame(),\n",
    "        pd.concat(cap_holds_dfs) if cap_holds_dfs else pd.DataFrame(),\n",
    "        pd.concat(dead_money_dfs) if dead_money_dfs else pd.DataFrame(),\n",
    "        pd.concat(summary_dfs) if summary_dfs else pd.DataFrame()\n",
    "    )\n",
    "\n",
    "# Example usage\n",
    "\n",
    "teams = ['ATL', 'BOS', 'BKN', 'CHA', 'CHI', 'CLE', 'DAL', 'DEN', 'DET', 'GSW', \n",
    "         'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK', \n",
    "         'OKC', 'ORL', 'PHI', 'PHX', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS']\n",
    "#teams=['ATL']\n",
    "salary_df, options_df, cap_holds_df, dead_money_df, summary_df = scrape_all_teams(teams)\n",
    "\n",
    "# Save results\n",
    "salary_df.to_csv('nba_salaries.csv', index=False)\n",
    "options_df.to_csv('nba_options.csv', index=False)\n",
    "cap_holds_df.to_csv('nba_cap_holds.csv', index=False)\n",
    "dead_money_df.to_csv('nba_dead_money.csv', index=False)\n",
    "summary_df.to_csv('nba_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
